{
 "metadata": {
  "name": "",
  "signature": "sha256:bcb93303eab84e431b9dbf8b383de21ee25fc7cc0458c3b95769cbc3d9ef9d58"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "from lxml import etree\n",
      "import re\n",
      "from StringIO import StringIO\n",
      "\n",
      "files = glob.glob('./**/*.html')\n",
      "files = filter(lambda x: \"example\" not in x, files)\n",
      "files = filter(lambda x: \".json.html\" not in x, files)\n",
      "files = filter(lambda x: \".xml.html\" not in x, files)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(files)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 109,
       "text": [
        "2367"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "files[500]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "'./site/enrollmentresponse-profiles.html'"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter(lambda x: \"medication.html\" in x, files)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 111,
       "text": [
        "['./site/medication-qicore-qicore-medication.html',\n",
        " './site/allergyintolerance-medication.html',\n",
        " './site/medication-daf-dafmedication.html',\n",
        " './site/medication.html']"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = './site/medication.html'\n",
      "\n",
      "def nodes(at):\n",
      "    yield at\n",
      "    for c in at.iterchildren():\n",
      "        for v in nodes(c):\n",
      "            yield v\n",
      "\n",
      "def matches(root, section_predicate, node_predicate):\n",
      "    found = None\n",
      "    for n in nodes(root):\n",
      "        if section_predicate(n): found = n\n",
      "        if node_predicate(n): yield (found, n)\n",
      "\n",
      "def text(e):\n",
      "    if e:\n",
      "        ret = \" \".join(e.xpath(\".//text()\"))\n",
      "        return re.sub(\"\\s+\", \" \", ret)\n",
      "    return \"\"\n",
      "\n",
      "def process_file(f):\n",
      "    url = f.split(\"/\")[-1]\n",
      "    docs = {}\n",
      "    doc = docs[url] = {'url': url, 'text': \"\"}\n",
      "    f = open(f).read().replace(\"&nbsp;\", \"\")\n",
      "    mydoc = etree.parse(StringIO(f))\n",
      "\n",
      "    for e in mydoc.xpath('//title'):\n",
      "        doc['title'] =  text(e)\n",
      "\n",
      "\n",
      "\n",
      "    for (section, elt) in matches(\n",
      "        mydoc.getroot(),\n",
      "        lambda x: x.tag == 'span' and \"class\" in x.attrib and \"sectioncount\" in x.attrib[\"class\"],\n",
      "        lambda x: x.tag in [\"ul\", \"h1\", \"h2\", \"h3\", \"p\", \"table\"]):\n",
      "        if not section:\n",
      "            doc['text'] += text(elt)\n",
      "        else:\n",
      "            if section.text not in docs:\n",
      "                docs[section.text] = {\n",
      "                    'url': \"%s#%s\"%(url, section.text),\n",
      "                    'title': text(elt.getprevious()),\n",
      "                    'text': \"\"}\n",
      "            docs[section.text]['text'] += text(elt)\n",
      "            \n",
      "    return docs.values()\n",
      "\n",
      "skipped = []\n",
      "alldocs = []\n",
      "for i, f in enumerate(files):\n",
      "    try:\n",
      "        alldocs += process_file(f)\n",
      "    except:\n",
      "        skipped += [f]\n",
      "    if i%100 == 0: print i\n",
      "\n",
      "\n",
      "import copy\n",
      "alldocs_orig = copy.copy(alldocs)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "400"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "600"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "700"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "800"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "900"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1400"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1600"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1700"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1800"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1900"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "js_str = json.dumps(alldocs, ofile)\n",
      "\n",
      "with open(\"alldocs.json\", \"w\") as ofile:\n",
      "    print >>ofile, js_str\n",
      "with open(\"alldocs.js\", \"w\") as ofile:\n",
      "    print >>ofile, \"var alldocs = %s\"%js_str"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = mydoc.xpath('//h2')[2]\n",
      "print nearestBefore(p, lambda x: x.tag == 'span' and \"class\" in x.attrib and \"sectioncount\" in x.attrib[\"class\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<Element span at 0x7f97a9fda758>\n"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "basetext = []\n",
      "for s in alldocs:\n",
      "    ww = s['text']\n",
      "    if 'title' in s: ww = s['title'] + \" \" + ww\n",
      "    basetext.append(\" \".join(words(ww)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.tokenize import WhitespaceTokenizer\n",
      "tok = WhitespaceTokenizer()\n",
      "\n",
      "allwords = defaultdict(int)\n",
      "\n",
      "def words(s):\n",
      "    ret =  filter(lambda x: len(x) > 2, tok.tokenize(s.lower()))\n",
      "    for w in ret:\n",
      "        allwords[w] += 1\n",
      "    return ret\n",
      "for d in alldocs:\n",
      "    if 'title' in d:\n",
      "        d['title'] = words(d['title'])\n",
      "\n",
      "    if 'text' in d:\n",
      "        d['text'] = words(d['text'])\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allwords['prescription']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "173"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skipped[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "'./site/extension-iso21090-adxp-careof.html'"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alldocs[500]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "{'text': u\" \\xa9 HL7.org 2011+. FHIR DSTU (v0.5.0-5149) generated on Fri, Apr 3, 2015 14:32+1100. Links: What's a DSTU? | Version History | Specification Map | Compare to DSTU | | Propose a change \",\n",
        " 'title': '6.1.11 Resource List - Design Notes ',\n",
        " 'url': 'list-explanations.html#6.1.11'}"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "def dd():\n",
      "    return defaultdict(dd)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sourcenumidx = {}\n",
      "docnumidx = {}\n",
      "docnum = []\n",
      "for d in alldocs:\n",
      "    n = len(docnum)\n",
      "    docnumidx[d['url']] = n\n",
      "    sourcenumidx[n] = d\n",
      "    docnum.append(d['url'])\n",
      "idx = defaultdict(dict)\n",
      "\n",
      "\n",
      "\n",
      "for d in alldocs:\n",
      "    num = docnumidx[d['url']]\n",
      "    if 'title' in d:\n",
      "        for t in d['title']:\n",
      "            if num not in idx[t]:\n",
      "                idx[t][num] = 0\n",
      "            idx[t][num] += 10\n",
      "            if idx[t][num]== 0:\n",
      "                raise\n",
      "    for t in d['text']:\n",
      "        if num not in idx[t]:\n",
      "            idx[t][num] = 0\n",
      "        idx[t][num] += 1\n",
      "        if idx[t][num]== 0:\n",
      "            raise\n",
      "\n",
      "for (word, counts) in idx.iteritems():\n",
      "    for (doc, count) in counts.iteritems():\n",
      "        total_len = len(sourcenumidx[doc]['text'])\n",
      "        if 'title' in  sourcenumidx[doc]:\n",
      "            total_len += len(sourcenumidx[doc]['title'])\n",
      "        try:\n",
      "            counts[doc] = int((1.0*count / total_len) * 10000)\n",
      "        except:\n",
      "            print word, counts, count, total_len\n",
      "print idx['percentage']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{1472: 9, 2106: 13, 1228: 14}\n"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "idxmap = {}  \n",
      "\n",
      "words = idx.keys()\n",
      "random.shuffle(words)\n",
      "print words[1000:1010]\n",
      "\n",
      "def idxmap_insert(topword, word=None, submap=idxmap):\n",
      "    if word == None: word = topword\n",
      "    if len(word) == 0:\n",
      "        submap['$']=idx[topword]\n",
      "        return\n",
      "    if word[0] not in submap:\n",
      "        submap[word[0]] = {}\n",
      "    idxmap_insert(topword, word[1:], submap[word[0]])\n",
      "        \n",
      "\n",
      "for w in words:\n",
      "    idxmap_insert(w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'431249008', u'437955002', u'medicationadministration)', 'clinicalimpression5.22.3', u'252212', u'systolic', u'570001', u'36747-4', u'immunisation', u'posted']\n"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print idxmap['p']['e']['r']['c']['e']['n']['t']['a']['g']['e']['$']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{1472: 9, 2106: 13, 1228: 14}\n"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "js_str = json.dumps({'idx': idx, 'docnames': docnum}, separators=(',', ':'))\n",
      "\n",
      "with open(\"alldocs-idx.json\", \"w\") as ofile:\n",
      "    print >>ofile, js_str\n",
      "with open(\"alldocs-idx.js\", \"w\") as ofile:\n",
      "    print >>ofile, \"var cache = %s\"%js_str"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "js_str = json.dumps(basetext, separators=(',', ':'))\n",
      "\n",
      "with open(\"basetext.json\", \"w\") as ofile:\n",
      "    print >>ofile, js_str\n",
      "with open(\"basetext.js\", \"w\") as ofile:\n",
      "    print >>ofile, \"var docs = %s\"%js_str"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "js_str = json.dumps({'idx': idxmap, 'docnames': docnum}, separators=(',', ':'))\n",
      "\n",
      "with open(\"idxmap.json\", \"w\") as ofile:\n",
      "    print >>ofile, js_str\n",
      "with open(\"idxmap.js\", \"w\") as ofile:\n",
      "    print >>ofile, \"var idxmap = %s\"%js_str"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    }
   ],
   "metadata": {}
  }
 ]
}